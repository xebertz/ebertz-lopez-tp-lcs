= TP Inicial - Laboratorio de Construcción de Software
Ebertz Ximena <xebertz@campus.ungs.edu.ar>; Gross Pablo <pablorubengross@gmail.com>; López Gonzalo <gonzagonzalopez20@gmail.com>
v1, {docdate}
:toc:
:title-page:
:toc-title: Secciones
:numbered:
:source-highlighter: highlight.js
:tabsize: 4
:nofooter:
:pdf-page-margin: [3cm, 3cm, 3cm, 3cm]

== Introducción

En el transcurso de este documento, se abordará de manera exhaustiva el proceso de preparación de los datos destinados a alimentar nuestro sistema de detección de enfermedades oculares. Además, se proporcionarán argumentos sólidos que respaldan la elección de un modelo de _Machine Learning_ específico. Finalmente, se arrojará luz sobre el funcionamiento intrínseco del proceso de entrenamiento de dicho modelo.

== Desarrollo

=== Detección de Retinopatía Diabética

Nuestro sistema está destinado a la detección de retinopatías diabéticas y su severidad a través del análisis de imágenes de fondo de ojo, tanto en el lado derecho como en el izquierdo, provenientes de un conjunto de datos de pacientes reales. Este conjunto de datos cuenta con aproximadamente 35.000 imágenes, y las etiquetas de las mismas. Cada etiqueta corresponde a un nivel de retinopatía diabética ocular, que puede ser 0, 1, 2, 3 o 4. Nuestro objetivo es, dada una imagen de fondo de ojo, poder detectar el nivel de esta enfermedad en el paciente.

Para desarrollar el sistema estamos utilizando Google Colab, el cual es un servicio en línea gratuito ofrecido por Google que permite a los usuarios escribir y ejecutar código de Python en un entorno de bloc de notas basado en la nube.

=== Datos

==== Exploración y análisis de datos

Del dataset elegido, utilizamos las imágenes pertenecientes a la carpeta `resized_train_cropped`, y las etiquetas del archivo `trainLabels.csv`.

Sabemos que para entrenar a una Inteligencia Artificial con aprendizaje supervisado, necesitamos un conjunto de datos homogéneo y etiquetado. Observamos que en el dataset elegido había al rededor de 25.000 imágenes con la etiqueta 0, lo que puede ser contraproducente. Si hay demasiadas muestras de una sola clase, la IA puede aprender incorrectamente. Por esto, decidimos utilizar 4.000 imágenes de esta clase, dejando un total de 13.306 imágenes para entrenamiento, testing y validación. Estas imágenes se convirtieron en tensores, para que puedan ser procesadas correctamente por la inteligencia artificial. Las analizamos en formato 100 x 100, con tres canales de color: RGB.

Luego, teníamos que convertir las etiquetas del dataset un formato que pueda entender la IA. Para esto, transformamos cada etiqueta en un tensor de cinco posiciones, con todos sus valores en cero, y el valor de la posición correspondiente al número de etiqueta, en uno. De esta forma, tenemos los siguientes tipos de etiquetas:

- 0: `[1 0 0 0 0]`
- 1: `[0 1 0 0 0]`
- 2: `[0 0 1 0 0]`
- 3: `[0 0 0 1 0]`
- 4: `[0 0 0 0 1]`

Finalmente, decidimos utilizar transformaciones en las imágenes elegidas, para que la inteligencia artificial no aprenda a identificar la enfermedad en un solo tipo de imágen, y sea capaz de identificarla en imágenes con más o menos zoom, tamaño, opacidad, etcétera.

=== Selección de modelos

Debido a la estructura de nuestros datos, utilizamos un modelo de aprendizaje supervisado. Existen diversos tipos de modelos de aprendizaje supervisado, como árboles de decisión, regresión lineal, deep learning, entre otros. Decidimos que para nuestro caso, ya que analizamos imágenes, las mejores opciones serían _redes neuronales convolucionales_, pertenecientes al campo de deep learning, y _redes neuronales densas_. Sus características son:

- _redes neuronales convolucionales:_ estas redes tienen la particularidad de incluir en su arquitectura dos tipos más de neuronas en sus capas intermedias. Las neuronas _convolutivas_ analizas un pixel de la imagen, aplicándole filtros a los pixeles subyacentes para determinar su utilidad al modelo; y las neuronas de _pooling_ agrupan estos pixeles en matrices de un tamaño determinado. En esos grupos de pixeles se extrae el de mayor valor, generando así una imagen de donde se resalten las características necesarias para el modelo.
- _redes neuronales densas:_ este tipo de red es sencilla. Tiene conexiones completas entre las neuronas de cada capa, sin estructura jerárquica. Cada neurona recibe entradas de todas las neuronas previas y envía salidas a todas las siguientes, lo que le permite aprender patrones y relaciones en los datos. Requiere gran cantidad de datos para un buen rendimiento, y una vez entrenada, en general analiza datos de manera veloz, con poco nivel de error. Por este motivo, elegimos este modelo para comparar con el anterior

Entrenamos ambos modelos, con la finalidad de observar cuál se adapta mejor.

=== Entrenamiento de modelos

El modelo de red neuronal convolucional tiene trece capas, de las cuales cuatro son _convolucionales_, es decir, leen pixeles de la imagen; y dos son de tipo _max pooling_, que realizan el trabajo de agrupación y extracción de pixeles de mayor valor. Se completa con capas _densas_ y de _dropout_, para mejorar la predicción.

El modelo de red neuronal densa, en cambio, tiene siete capas densas, con 869 neuronas en total, y una capa de entrada de tipo flatten.

Ambos modelos implementan la función de activación _ReLu_, que permite mejoras en los ajustes de los pesos de la red; y están compilados con el optimizador "Adam", que permite una ejecución del entrenamiento con mayor velocidad.

Estos modelos fueron entrenados con los mismos datos.

== Dificultades

A lo largo de esta fase del proyecto, nos encontramos con diversas dificultades, entre las que se incluyen:

* _entrada de datos para entrenar el modelo:_ hubo conflictos con la manera en la que consumimos los datos, de tal forma que no se podía entrenar el modelo por que los datos no se encontraban en el formato que el modelo pedía.
* _precisión de los modelos:_ ambos modelos necesitan mucho entrenamiento para alcanzar los niveles deseados de precisión.
* _limitaciones de hardware:_ debido a la cantidad de imágenes, no podemos procesar imágenes de resoluciones mayores a 100 x 100 pixeles.
* _ajuste de parámetros:_ en las redes neuronales hay muchos parámetros a ajustar, que juegan papeles importantes en la precisión de la red. Este ajuste, en general, es a base de prueba y error; por lo que todavía seguimos probando nuestras redes, para lograr una mayor precisión.

== Conclusión

Se han identificado desafíos en el proceso de entrenamiento del modelo neuronal, y se reconoce la necesidad de realizar un mayor desarrollo con el objetivo de perfeccionar el modelo, permitiéndole captar de manera más efectiva los patrones necesarios para un aprendizaje óptimo.
