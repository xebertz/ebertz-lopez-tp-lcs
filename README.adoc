= TP Inicial - Laboratorio de Construcción de Software
Ebertz Ximena <xebertz@campus.ungs.edu.ar>; Gross Pablo <pablorubengross@gmail.com>; López Gonzalo <gonzagonzalopez20@gmail.com>
v1, {docdate}
:toc:
:title-page:
:toc-title: Secciones
:numbered:
:source-highlighter: highlight.js
:tabsize: 4
:nofooter:
:pdf-page-margin: [3cm, 3cm, 3cm, 3cm]

== Introducción

En el transcurso de este documento, se abordará de manera exhaustiva el proceso de preparación de los datos destinados a alimentar nuestro sistema de detección de enfermedades oculares. Además, se proporcionarán argumentos sólidos que respaldan la elección de un modelo de _Machine Learning_ específico. Finalmente, se arrojará luz sobre el funcionamiento intrínseco del proceso de entrenamiento de dicho modelo.

== Desarrollo

=== Detección de Retinopatía Diabética

Nuestro sistema está destinado a la detección de retinopatías diabéticas y su severidad a través del análisis de imágenes de fondo de ojo, tanto en el lado derecho como en el izquierdo, provenientes de un conjunto de datos de pacientes reales. Este conjunto de datos cuenta con aproximadamente 35.000 imágenes, y las etiquetas de las mismas. Cada etiqueta corresponde a un nivel de retinopatía diabética ocular, que puede ser 0, 1, 2, 3 o 4. Nuestro objetivo es, dada una imagen de fondo de ojo, poder detectar el nivel de esta enfermedad en el paciente.

Para desarrollar el sistema estamos utilizando Google Colab, el cual es un servicio en línea gratuito ofrecido por Google que permite a los usuarios escribir y ejecutar código de Python en un entorno de bloc de notas basado en la nube.

=== Datos

==== Exploración y análisis de datos

Del dataset elegido, utilizamos las imágenes pertenecientes a la carpeta `resized_train_cropped`, y las etiquetas del archivo `trainLabels.csv`.

Sabemos que para entrenar a una Inteligencia Artificial con aprendizaje supervisado, necesitamos un conjunto de datos homogéneo y etiquetado. Observamos que en el dataset elegido había al rededor de 25.000 imágenes con la etiqueta 0, lo que puede ser contraproducente. Si hay demasiadas muestras de una sola clase, la IA puede aprender incorrectamente. Por esto, decidimos utilizar 4.000 imágenes de esta clase, dejando un total de 13.306 imágenes para entrenamiento, testing y validación. Estas imágenes se convirtieron en tensores, para que puedan ser procesadas correctamente por la inteligencia artificial. Las analizamos en formato 100 x 100, con tres canales de color: RGB.

Luego, teníamos que convertir las etiquetas del dataset un formato que pueda entender la IA. Para esto, transformamos cada etiqueta en un tensor de cinco posiciones, con todos sus valores en cero, y el valor de la posición correspondiente al número de etiqueta, en uno. De esta forma, tenemos los siguientes tipos de etiquetas:

- 0: `[1 0 0 0 0]`
- 1: `[0 1 0 0 0]`
- 2: `[0 0 1 0 0]`
- 3: `[0 0 0 1 0]`
- 4: `[0 0 0 0 1]`

Finalmente, decidimos utilizar transformaciones en las imágenes elegidas, para que la inteligencia artificial no aprenda a identificar la enfermedad en un solo tipo de imágen, y sea capaz de identificarla en imágenes con más o menos zoom, tamaño, opacidad, etcétera.

=== Selección de modelo

Debido a la estructura de nuestros datos, utilizamos un modelo de aprendizaje supervisado. Existen diversos tipos de modelos de aprendizaje supervisado, como árboles de decisión, regresión lineal, deep learning, entre otros. Decidimos que para nuestro caso, ya que analizamos imágenes, las mejores opciones serían _redes neuronales convolucionales_, pertenecientes al campo de deep learning, y _redes neuronales densas_. Sus característica son:

- redes neuronales convolucionales:
- redes neuronales densas:




Por este caso mismo de análisis de imágenes recurrimos a utilizar el modelo de _Deep Learning_ con redes neuronales convolucionales, el cual es optimo para estos mismos. Esto se debe a la capacidad de la red neuronal convolutiva de poder segmentar y enfocar aplicando contexto con ecuaciones en los nodos. Permitiendo así el análisis de una imagen compleja de manera rápida.

El análisis completo de las imágenes es posible por las capas convolutivas de la red neuronal. Estas capas agarran un pixel de la imagen y se aplican filtros a los pixeles subyacentes para determinar su utilidad al modelo. Después se agrupan los pixeles en cuadrados del tamaño que uno determine (en nuestro caso 2x2) y en esos grupos de pixeles se extrae el de mayor valor, generando así una imagen de donde se resalten las características necesarias para el modelo.

=== Entrenamiento de modelo

El modelo que se encuentra en uso utiliza una red neuronal de 10 capas las cuales 4 de ellas son convolucionales. Este mismo modelo se encarga de consumir imágenes de fondos de ojos para poder determinar la seriedad de la retinopatía diabética a través del análisis de patrones encontrados en las imágenes con las cuales el modelo allá entrenado.

Esto se produce al ingresar las imágenes a la red neuronal para que pueda distinguir patrones que se encuentren en varias imágenes presentadas con su diagnostico ya presente.

== Dificultades

A lo largo de esta fase del proyecto, nos encontramos con diversas dificultades, entre las que se incluyen:

    * Entrada de datos para entrenar el modelo: Hubo conflictos con la manera en la que consumimos los datos, de tal forma que no se podía entrenar el modelo por que los datos no se encontraban en el formato que el modelo pedía.

* Que los resultados no tengan sentido en el modelo de la IA: Una vez entrenado el modelo se trato de verificar su precisión pero este en ves de dar resultados de 0 o 1 para determinar la enfermedad ocular presente daba un valor superior a 1.

    * Una ves entrenado el modelo se trato de verificar su precision pero este en ves de dar resultados de 0 o 1. Para determinar la enfermedad ocular presente daba un valor superior a 1

* Precisión del modelo: El modelo entrenado con el nuevo dataset presente puede entrenar por varias "Epochs" y aún no puede superar el 0,4624 de precisión.

== Conclusión

Se han identificado desafíos en el proceso de entrenamiento del modelo neuronal, y se reconoce la necesidad de realizar un mayor desarrollo con el objetivo de perfeccionar el modelo, permitiéndole captar de manera más efectiva los patrones necesarios para un aprendizaje óptimo.
